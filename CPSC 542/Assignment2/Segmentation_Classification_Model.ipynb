{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CNN Libaries (tensorflow.keras)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./augmented-forest-segmentation\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/quadeer15sh/augmented-forest-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegmentationClassificationModel: \n",
    "    \n",
    "    def __init__(self, datasetCSVFilePath, numClasses, datasetFolderPath, X_col, y_col, img_height, img_width, img_channels):\n",
    "        self.datasetCSVFilePath = datasetCSVFilePath\n",
    "        self.datasetFolderPath = datasetFolderPath\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.img_channels = img_channels\n",
    "        self.numClasses = numClasses\n",
    "    \n",
    "    def getDataset(self):\n",
    "        \n",
    "        myDatasetCSV = pd.read_csv(self.datasetCSVFilePath)\n",
    "        # self.myDataset = pd.DataFrame(columns= [self.X_col, self.y_col])\n",
    "        self.X = np.zeros((len(myDatasetCSV), self.img_height, self.img_width, self.img_channels), dtype = np.uint8)\n",
    "        self.y = np.zeros((len(myDatasetCSV), self.img_height, self.img_width, 1), dtype = bool)\n",
    "        i = 0\n",
    "        \n",
    "        \n",
    "        for index, row in myDatasetCSV.iterrows():\n",
    "            \n",
    "            imagePath = self.datasetFolderPath + \"/images/\" + row[self.X_col]\n",
    "            myImage = imread(imagePath)[:,:,:self.img_channels]  \n",
    "            myImage = resize(myImage, (self.img_height, self.img_width), mode='constant', preserve_range=True)\n",
    "            self.X[i] = myImage\n",
    "            \n",
    "            # Load mask\n",
    "            maskDir = os.path.join(self.datasetFolderPath, \"masks\")\n",
    "            maskArray = np.zeros((self.img_height, self.img_width, 1), dtype=bool)\n",
    "            for mask_file in os.listdir(maskDir):\n",
    "                if mask_file.startswith(row[self.y_col]):\n",
    "                    maskPath = os.path.join(maskDir, mask_file)\n",
    "                    myMask = imread(maskPath)[:, :, 0]  # Assuming grayscale\n",
    "                    myMask = np.expand_dims(resize(myMask, (self.img_height, self.img_width), mode='constant',  \n",
    "                                        preserve_range=True), axis=-1)\n",
    "                    maskArray = np.maximum(maskArray, myMask)\n",
    "        \n",
    "        self.y[i] = maskArray\n",
    "        i += 1\n",
    "    \n",
    "    def trainTestSplit(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2)\n",
    "    \n",
    "    def preProcessing(self):\n",
    "        \n",
    "        self.X_train = self.X_train / 255.0\n",
    "        self.X_test = self.X_test / 255.0\n",
    "        \n",
    "    def trainValSplit(self):\n",
    "        \n",
    "        self.X_train, X_val, self.y_train, y_val = train_test_split(self.X_train, self.y_train, test_size = 0.2)\n",
    "        \n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "    \n",
    "    def displayClassImages(self):\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(6):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.X_train[i])\n",
    "            plt.xlabel(self.y_train[i])\n",
    "        plt.show()\n",
    "            \n",
    "    def augmentDataset(self, h_flip, v_flip, rot_range, myZoom_range):\n",
    "        \n",
    "        image_generator = ImageDataGenerator(\n",
    "            horizontal_flip = h_flip,\n",
    "            vertical_flip = v_flip,\n",
    "            rotation_range = rot_range,\n",
    "            zoom_range = myZoom_range)\n",
    "        \n",
    "        self.train_generator = image_generator.flow(self.X_train, self.y_train)\n",
    "        \n",
    "    # def cnnModel(self, numConvolutions, numDropout, dropoutRate, isBatchNormalization):\n",
    "        \n",
    "    #     myNumDropout = numDropout\n",
    "        \n",
    "    #     self.model = models.Sequential()\n",
    "    #     self.model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(self.img_height, self.img_width, self.img_channels)))\n",
    "    #     self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "    #     for i in range(0, numConvolutions):\n",
    "            \n",
    "    #         self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    #         self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "            \n",
    "    #         if(myNumDropout > 0):\n",
    "                \n",
    "    #             self.model.add(Dropout(dropoutRate))\n",
    "    #             myNumDropout -= 1\n",
    "                \n",
    "    #         if(isBatchNormalization == True):\n",
    "                \n",
    "    #             self.model.add(BatchNormalization())\n",
    "        \n",
    "    #     self.model.add(layers.Flatten())\n",
    "    #     self.model.add(layers.Dense(64, activation='relu'))\n",
    "    #     self.model.add(layers.Dense(self.num_classes))\n",
    "    \n",
    "    def uNetModel(self, dropoutRate):\n",
    "        \n",
    "        self.inputs = tf.keras.layers.Input((self.img_height, self.img_width, self.img_channels))\n",
    "        \n",
    "        #Contraction path\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(self.inputs)\n",
    "        c1 = tf.keras.layers.Dropout(dropoutRate)(c1)\n",
    "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "        b1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "        r1 = tf.keras.layers.ReLU()(b1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2, 2))(r1)\n",
    "\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "        c2 = tf.keras.layers.Dropout(dropoutRate)(c2)\n",
    "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "        b2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "        r2 = tf.keras.layers.ReLU()(b2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2, 2))(r2)\n",
    "        \n",
    "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "        c3 = tf.keras.layers.Dropout(dropoutRate)(c3)\n",
    "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "        b3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "        r3 = tf.keras.layers.ReLU()(b3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2, 2))(r3)\n",
    "        \n",
    "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "        c4 = tf.keras.layers.Dropout(dropoutRate)(c4)\n",
    "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "        b4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "        r4 = tf.keras.layers.ReLU()(b4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(r4)\n",
    "        \n",
    "        c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "        b5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "        r5 = tf.keras.layers.ReLU()(b5)\n",
    "        c5 = tf.keras.layers.Dropout(dropoutRate)(r5)\n",
    "        c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "        # Expansive path \n",
    "        u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "        u6 = tf.keras.layers.BatchNormalization()(u6)\n",
    "        u6 = tf.keras.layers.ReLU()(u6)\n",
    "\n",
    "        \n",
    "        u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "        u7 = tf.keras.layers.BatchNormalization()(u7)\n",
    "        u7 = tf.keras.layers.ReLU()(u7)\n",
    "\n",
    "        \n",
    "        u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "        u8 = tf.keras.layers.BatchNormalization()(u8)\n",
    "        u8 = tf.keras.layers.ReLU()(u8)\n",
    "        \n",
    "        u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(u8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "        u9 = tf.keras.layers.BatchNormalization()(u9)\n",
    "        u9 = tf.keras.layers.ReLU()(u9)\n",
    "        \n",
    "        self.outputs = tf.keras.layers.Conv2D(self.numClasses, (1, 1), activation='sigmoid')(u9)\n",
    "\n",
    "        \n",
    "    \n",
    "    def compileAndFitCNNModel(self, learningRate, numEpochs):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = learningRate)\n",
    "        \n",
    "        \n",
    "        self.model.compile(optimizer= optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        self.history = self.model.fit(self.train_generator, epochs=numEpochs,\n",
    "                            validation_data=(self.X_val, self.y_val))\n",
    "        \n",
    "    def compileAndFitUNetModel(self, learningRate, numEpochs):\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs=[self.inputs], outputs=[self.outputs])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = learningRate)\n",
    "        \n",
    "        self.model.compile(optimizer= optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        self.history = self.model.fit(self.train_generator, epochs=numEpochs,\n",
    "                            validation_data=(self.X_val, self.y_val)) \n",
    "    \n",
    "    def showModelLoss(self):\n",
    "        \n",
    "        #graph of the loss function between the training data and the validiation data\n",
    "\n",
    "        plt.figure(figsize=(15, 16))\n",
    "\n",
    "        plt.subplot(4, 2, 2)\n",
    "        plt.plot(self.history.history['loss'], label='Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='val_Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        \n",
    "    def showModelAccuracy(self):    \n",
    "        \n",
    "        #graph of the accuracy between the training data and the validiation data\n",
    "\n",
    "        plt.figure(figsize=(15, 16))\n",
    "\n",
    "        plt.subplot(4, 2, 2)\n",
    "        plt.plot(self.history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "    \n",
    "    # def showSaliencyMap(self):\n",
    "\n",
    "    def showTable(self):\n",
    "        \n",
    "        # Extract accuracy, loss, validation accuracy, and validation loss values from the history object\n",
    "        history_dict = self.history.history\n",
    "        history_dict['epoch'] = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "        # Convert the history dictionary to a DataFrame\n",
    "        self.historyDF = pd.DataFrame(history_dict)\n",
    "        \n",
    "        for key in history_dict.keys():\n",
    "            if key != 'epoch':\n",
    "                history_dict[key] = [round(value, 3) for value in history_dict[key]]\n",
    "\n",
    "        # Create a Matplotlib figure and axis\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Hide axes\n",
    "        ax.axis('off')\n",
    "        plt.title(\"Accuracy and Loss over Epochs\")\n",
    "\n",
    "        # Create the table\n",
    "        ax.table(cellText=self.historyDF.values,\n",
    "                 colLabels=self.historyDF.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
