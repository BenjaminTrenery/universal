{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [tag for (word, tag) in brown.tagged_words(categories = \"news\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"I do not like green eggs and ham, I do not like them Same I am\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Same', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories = \"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_sents = brown.sents(categories = \"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.accuracy(brown_tagged_sents) # u can also use .evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    ('.*ing$', 'VBG'), \n",
    "    ('.*ed', 'VBD'),\n",
    "    ('.*es$', \"VBZ\"),\n",
    "    ('.*ould$', \"MD\"),\n",
    "    ('.*\\'s$', 'NN$'),\n",
    "    ('.*s$', 'NNS'), \n",
    "    ('^-?[0-9]+(\\.[0-9]+)?', \"CD\"),\n",
    "    (\".*\", \"NN\")\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1950/108676848.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  regexp_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20144400023867773"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', 'NN'),\n",
       " ('Only', 'NN'),\n",
       " ('a', 'NN'),\n",
       " ('relative', 'NN'),\n",
       " ('handful', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('such', 'NN'),\n",
       " ('reports', 'NNS'),\n",
       " ('was', 'NNS'),\n",
       " ('received', 'VBD'),\n",
       " (\"''\", 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('jury', 'NN'),\n",
       " ('said', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('``', 'NN'),\n",
       " ('considering', 'VBG'),\n",
       " ('the', 'NN'),\n",
       " ('widespread', 'NN'),\n",
       " ('interest', 'NN'),\n",
       " ('in', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('election', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('voters', 'NNS'),\n",
       " ('and', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('size', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('this', 'NNS'),\n",
       " ('city', 'NN'),\n",
       " (\"''\", 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.tag(brown_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(brown.words(categories= \"news\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories= \"news\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_words = fd.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "likely_tags = dict((word, cfd[word].max()) for (word,_) in most_freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 'AT',\n",
       " ',': ',',\n",
       " '.': '.',\n",
       " 'of': 'IN',\n",
       " 'and': 'CC',\n",
       " 'to': 'TO',\n",
       " 'a': 'AT',\n",
       " 'in': 'IN',\n",
       " 'for': 'IN',\n",
       " 'The': 'AT',\n",
       " 'that': 'CS',\n",
       " '``': '``',\n",
       " 'is': 'BEZ',\n",
       " 'was': 'BEDZ',\n",
       " \"''\": \"''\",\n",
       " 'on': 'IN',\n",
       " 'at': 'IN',\n",
       " 'with': 'IN',\n",
       " 'be': 'BE',\n",
       " 'by': 'IN',\n",
       " 'as': 'CS',\n",
       " 'he': 'PPS',\n",
       " 'said': 'VBD',\n",
       " 'his': 'PP$',\n",
       " 'will': 'MD',\n",
       " 'it': 'PPS',\n",
       " 'from': 'IN',\n",
       " 'are': 'BER',\n",
       " ';': '.',\n",
       " 'an': 'AT',\n",
       " 'has': 'HVZ',\n",
       " '--': '--',\n",
       " 'had': 'HVD',\n",
       " 'who': 'WPS',\n",
       " 'have': 'HV',\n",
       " 'not': '*',\n",
       " 'Mrs.': 'NP',\n",
       " 'were': 'BED',\n",
       " 'this': 'DT',\n",
       " 'which': 'WDT',\n",
       " 'would': 'MD',\n",
       " 'their': 'PP$',\n",
       " 'been': 'BEN',\n",
       " 'they': 'PPSS',\n",
       " 'He': 'PPS',\n",
       " 'one': 'CD',\n",
       " 'I': 'PPSS',\n",
       " 'but': 'CC',\n",
       " 'its': 'PP$',\n",
       " 'or': 'CC',\n",
       " ')': ')',\n",
       " 'more': 'AP',\n",
       " 'Mr.': 'NP',\n",
       " '(': '(',\n",
       " 'up': 'RP',\n",
       " 'all': 'ABN',\n",
       " 'out': 'RP',\n",
       " 'last': 'AP',\n",
       " 'two': 'CD',\n",
       " 'other': 'AP',\n",
       " ':': ':',\n",
       " 'new': 'JJ',\n",
       " 'first': 'OD',\n",
       " 'than': 'IN',\n",
       " 'year': 'NN',\n",
       " 'A': 'AT',\n",
       " 'about': 'IN',\n",
       " 'there': 'EX',\n",
       " 'when': 'WRB',\n",
       " 'home': 'NN',\n",
       " 'after': 'IN',\n",
       " 'In': 'IN',\n",
       " 'also': 'RB',\n",
       " 'It': 'PPS',\n",
       " 'over': 'IN',\n",
       " 'into': 'IN',\n",
       " 'no': 'AT',\n",
       " 'But': 'CC',\n",
       " 'made': 'VBN',\n",
       " 'only': 'AP',\n",
       " 'her': 'PP$',\n",
       " 'years': 'NNS',\n",
       " 'time': 'NN',\n",
       " 'three': 'CD',\n",
       " 'them': 'PPO',\n",
       " 'some': 'DTI',\n",
       " 'can': 'MD',\n",
       " 'him': 'PPO',\n",
       " 'New': 'JJ-TL',\n",
       " 'any': 'DTI',\n",
       " 'state': 'NN',\n",
       " '?': '.',\n",
       " 'President': 'NN-TL',\n",
       " 'before': 'IN',\n",
       " 'week': 'NN',\n",
       " 'could': 'MD',\n",
       " 'under': 'IN',\n",
       " 'against': 'IN',\n",
       " 'we': 'PPSS',\n",
       " 'what': 'WDT'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model = likely_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45578495136941344"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tagger.accuracy(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = brown.sents(categories= \"news\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '``'),\n",
       " ('Only', None),\n",
       " ('a', 'AT'),\n",
       " ('relative', None),\n",
       " ('handful', None),\n",
       " ('of', 'IN'),\n",
       " ('such', None),\n",
       " ('reports', None),\n",
       " ('was', 'BEDZ'),\n",
       " ('received', None),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('the', 'AT'),\n",
       " ('jury', None),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('``', '``'),\n",
       " ('considering', None),\n",
       " ('the', 'AT'),\n",
       " ('widespread', None),\n",
       " ('interest', None),\n",
       " ('in', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('election', None),\n",
       " (',', ','),\n",
       " ('the', 'AT'),\n",
       " ('number', None),\n",
       " ('of', 'IN'),\n",
       " ('voters', None),\n",
       " ('and', 'CC'),\n",
       " ('the', 'AT'),\n",
       " ('size', None),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('city', None),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model = likely_tags, backoff= nltk.DefaultTagger(\"NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5817769556656125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tagger.accuracy(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.accuracy(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(brown_tagged_sents) * .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = brown_tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.accuracy(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.accuracy(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('population', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('Congo', 'NP'),\n",
       " ('is', 'BEZ'),\n",
       " ('13.5', None),\n",
       " ('million', None),\n",
       " (',', None),\n",
       " ('divided', None),\n",
       " ('into', None),\n",
       " ('at', None),\n",
       " ('least', None),\n",
       " ('seven', None),\n",
       " ('major', None),\n",
       " ('``', None),\n",
       " ('culture', None),\n",
       " ('clusters', None),\n",
       " (\"''\", None),\n",
       " ('and', None),\n",
       " ('innumerable', None),\n",
       " ('tribes', None),\n",
       " ('speaking', None),\n",
       " ('400', None),\n",
       " ('separate', None),\n",
       " ('dialects', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.tag(brown_sents[4203])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger(\"NN\")\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff= t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff= t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452108043456593"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.accuracy(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"t2.pk1\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(t2, output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = open(\"t2.pk1\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Chapman University was founded in 1861 in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chapman', 'NP'),\n",
       " ('University', 'NN-TL'),\n",
       " ('was', 'BEDZ'),\n",
       " ('founded', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('1861', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('California', 'NP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tags = [tag for sent in brown.sents(categories= \"humor\")\n",
    "             for (word,tag) in t2.tag(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_tags = [tag for (word, tag) in brown.tagged_words(categories= \"humor\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"confusionmatrix.txt\", \"w\")\n",
    "f.write((str(nltk.ConfusionMatrix(gold_tags, test_tags))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
