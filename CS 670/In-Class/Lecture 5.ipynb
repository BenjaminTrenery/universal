{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg, nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.Text(gutenberg.words(\"melville-moby_dick.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "moby.findall(\"<a> (<.*>) <man>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = nltk.Text(nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat.findall(\"<.*> <.*> <bro>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_learned = nltk.Text(brown.words(categories = [\"hobbies\", \"learned\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "hobbies_learned.findall(\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\" It is for us the living, to be dedicated here to the unfinished work \n",
    "which they who fought here have thus far so nobly advanced\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It is for us the living, to be dedicated here to the unfinished work \\nwhich they who fought here have thus far so nobly advanced\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tokens = word_tokenize(raw)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'for',\n",
       " 'us',\n",
       " 'the',\n",
       " 'live',\n",
       " ',',\n",
       " 'to',\n",
       " 'be',\n",
       " 'dedic',\n",
       " 'here',\n",
       " 'to',\n",
       " 'the',\n",
       " 'unfinish',\n",
       " 'work',\n",
       " 'which',\n",
       " 'they',\n",
       " 'who',\n",
       " 'fought',\n",
       " 'here',\n",
       " 'have',\n",
       " 'thu',\n",
       " 'far',\n",
       " 'so',\n",
       " 'nobli',\n",
       " 'advanc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'for',\n",
       " 'us',\n",
       " 'the',\n",
       " 'liv',\n",
       " ',',\n",
       " 'to',\n",
       " 'be',\n",
       " 'ded',\n",
       " 'her',\n",
       " 'to',\n",
       " 'the',\n",
       " 'unfin',\n",
       " 'work',\n",
       " 'which',\n",
       " 'they',\n",
       " 'who',\n",
       " 'fought',\n",
       " 'her',\n",
       " 'hav',\n",
       " 'thu',\n",
       " 'far',\n",
       " 'so',\n",
       " 'nobl',\n",
       " 'adv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PorterStemmer in module nltk.stem.porter object:\n",
      "\n",
      "class PorterStemmer(nltk.stem.api.StemmerI)\n",
      " |  PorterStemmer(mode='NLTK_EXTENSIONS')\n",
      " |  \n",
      " |  A word stemmer based on the Porter stemming algorithm.\n",
      " |  \n",
      " |      Porter, M. \"An algorithm for suffix stripping.\"\n",
      " |      Program 14.3 (1980): 130-137.\n",
      " |  \n",
      " |  See https://www.tartarus.org/~martin/PorterStemmer/ for the homepage\n",
      " |  of the algorithm.\n",
      " |  \n",
      " |  Martin Porter has endorsed several modifications to the Porter\n",
      " |  algorithm since writing his original paper, and those extensions are\n",
      " |  included in the implementations on his website. Additionally, others\n",
      " |  have proposed further improvements to the algorithm, including NLTK\n",
      " |  contributors. There are thus three modes that can be selected by\n",
      " |  passing the appropriate constant to the class constructor's `mode`\n",
      " |  attribute:\n",
      " |  \n",
      " |  - PorterStemmer.ORIGINAL_ALGORITHM\n",
      " |  \n",
      " |      An implementation that is faithful to the original paper.\n",
      " |  \n",
      " |      Note that Martin Porter has deprecated this version of the\n",
      " |      algorithm. Martin distributes implementations of the Porter\n",
      " |      Stemmer in many languages, hosted at:\n",
      " |  \n",
      " |      https://www.tartarus.org/~martin/PorterStemmer/\n",
      " |  \n",
      " |      and all of these implementations include his extensions. He\n",
      " |      strongly recommends against using the original, published\n",
      " |      version of the algorithm; only use this mode if you clearly\n",
      " |      understand why you are choosing to do so.\n",
      " |  \n",
      " |  - PorterStemmer.MARTIN_EXTENSIONS\n",
      " |  \n",
      " |      An implementation that only uses the modifications to the\n",
      " |      algorithm that are included in the implementations on Martin\n",
      " |      Porter's website. He has declared Porter frozen, so the\n",
      " |      behaviour of those implementations should never change.\n",
      " |  \n",
      " |  - PorterStemmer.NLTK_EXTENSIONS (default)\n",
      " |  \n",
      " |      An implementation that includes further improvements devised by\n",
      " |      NLTK contributors or taken from other modified implementations\n",
      " |      found on the web.\n",
      " |  \n",
      " |  For the best stemming, you should use the default NLTK_EXTENSIONS\n",
      " |  version. However, if you need to get the same results as either the\n",
      " |  original algorithm or one of Martin Porter's hosted versions for\n",
      " |  compatibility with an existing implementation or dataset, you can use\n",
      " |  one of the other modes instead.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PorterStemmer\n",
      " |      nltk.stem.api.StemmerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, mode='NLTK_EXTENSIONS')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  stem(self, word, to_lowercase=True)\n",
      " |      :param to_lowercase: if `to_lowercase=True` the word always lowercase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  MARTIN_EXTENSIONS = 'MARTIN_EXTENSIONS'\n",
      " |  \n",
      " |  NLTK_EXTENSIONS = 'NLTK_EXTENSIONS'\n",
      " |  \n",
      " |  ORIGINAL_ALGORITHM = 'ORIGINAL_ALGORITHM'\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.stem.api.StemmerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.PorterStemmer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LancasterStemmer in module nltk.stem.lancaster object:\n",
      "\n",
      "class LancasterStemmer(nltk.stem.api.StemmerI)\n",
      " |  LancasterStemmer(rule_tuple=None, strip_prefix_flag=False)\n",
      " |  \n",
      " |  Lancaster Stemmer\n",
      " |  \n",
      " |      >>> from nltk.stem.lancaster import LancasterStemmer\n",
      " |      >>> st = LancasterStemmer()\n",
      " |      >>> st.stem('maximum')     # Remove \"-um\" when word is intact\n",
      " |      'maxim'\n",
      " |      >>> st.stem('presumably')  # Don't remove \"-um\" when word is not intact\n",
      " |      'presum'\n",
      " |      >>> st.stem('multiply')    # No action taken if word ends with \"-ply\"\n",
      " |      'multiply'\n",
      " |      >>> st.stem('provision')   # Replace \"-sion\" with \"-j\" to trigger \"j\" set of rules\n",
      " |      'provid'\n",
      " |      >>> st.stem('owed')        # Word starting with vowel must contain at least 2 letters\n",
      " |      'ow'\n",
      " |      >>> st.stem('ear')         # ditto\n",
      " |      'ear'\n",
      " |      >>> st.stem('saying')      # Words starting with consonant must contain at least 3\n",
      " |      'say'\n",
      " |      >>> st.stem('crying')      #     letters and one of those letters must be a vowel\n",
      " |      'cry'\n",
      " |      >>> st.stem('string')      # ditto\n",
      " |      'string'\n",
      " |      >>> st.stem('meant')       # ditto\n",
      " |      'meant'\n",
      " |      >>> st.stem('cement')      # ditto\n",
      " |      'cem'\n",
      " |      >>> st_pre = LancasterStemmer(strip_prefix_flag=True)\n",
      " |      >>> st_pre.stem('kilometer') # Test Prefix\n",
      " |      'met'\n",
      " |      >>> st_custom = LancasterStemmer(rule_tuple=(\"ssen4>\", \"s1t.\"))\n",
      " |      >>> st_custom.stem(\"ness\") # Change s to t\n",
      " |      'nest'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LancasterStemmer\n",
      " |      nltk.stem.api.StemmerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, rule_tuple=None, strip_prefix_flag=False)\n",
      " |      Create an instance of the Lancaster stemmer.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  parseRules(self, rule_tuple=None)\n",
      " |      Validate the set of rules used in this stemmer.\n",
      " |      \n",
      " |      If this function is called as an individual method, without using stem\n",
      " |      method, rule_tuple argument will be compiled into self.rule_dictionary.\n",
      " |      If this function is called within stem, self._rule_tuple will be used.\n",
      " |  \n",
      " |  stem(self, word)\n",
      " |      Stem a word using the Lancaster stemmer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  default_rule_tuple = ('ai*2.', 'a*1.', 'bb1.', 'city3s.', 'ci2>', 'cn1...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.stem.api.StemmerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.LancasterStemmer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = \"\"\"\n",
    "Some corpora and packages are better than others\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = word_tokenize(raw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some', 'corpus', 'and', 'package', 'are', 'better', 'than', 'others']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(t) for t in tokens2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"\n",
    "'When I'm a Duchess, ' she said to herself, (not in a very hopeful tone though), \n",
    "'I won't have any pepper in my kitchen AT ALL. Soup does very well without--Maybe it's\n",
    "always pepper that makes people hot-tempered,'...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'When I'm a Duchess, ' she said to herself, (not in a very hopeful tone though), \\n'I won't have any pepper in my kitchen AT ALL. Soup does very well without--Maybe it's\\nalways pepper that makes people hot-tempered,'...\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n'When\",\n",
       " \"I'm\",\n",
       " 'a',\n",
       " 'Duchess,',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"\\n'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\\nalways\",\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\\n\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\" \", raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"'When\",\n",
       " \"I'm\",\n",
       " 'a',\n",
       " 'Duchess,',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\",\n",
       " '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"[ \\t\\n]+\", raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'm',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('\\W+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'That U.S.A. poster-print costs $12.40...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '''\n",
    "(?x)\n",
    "(?:[A-Z]\\.)+\n",
    "| \\w+(?:-\\w+)*\n",
    "| \\$?\\d+(?:\\.\\d+)?%?\n",
    "| \\.\\.\\.\n",
    "| [][.,;\"'?():-_`]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
